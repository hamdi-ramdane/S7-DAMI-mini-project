{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd #type:ignore\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold, KFold #type:ignore\n",
    "from sklearn.tree import DecisionTreeClassifier #type:ignore\n",
    "from sklearn.naive_bayes import GaussianNB #type:ignore\n",
    "from sklearn.metrics import accuracy_score, f1_score, classification_report, precision_score, recall_score  # type: ignore #type:ignore\n",
    "from sklearn.preprocessing import StandardScaler #type:ignore\n",
    "from imblearn.over_sampling import SMOTE, RandomOverSampler #type:ignore\n",
    "import matplotlib.pyplot as plt #type:ignore\n",
    "import seaborn as sns #type:ignore\n",
    "from sklearn.ensemble import RandomForestClassifier  # type: ignore"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. **Reading Data**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reading haberman.csv\n",
    "data = pd.read_csv(\"haberman.csv\")\n",
    "print(data.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. **Analysis and Visualization**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Number of rows and columns\n",
    "print(f\"Number of rows: {data.shape[0]}\")\n",
    "print(f\"Number of columns: {data.shape[1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Data types \n",
    "print(\"Data types:\\n\" + data.dtypes.to_string()) # Data types\n",
    "\n",
    "# Class distribution\n",
    "print(\"\\n\" + data['survival_status'].value_counts().to_string())  \n",
    "plt.figure(figsize=(3,2)) # Class distribution plot\n",
    "sns.countplot(x='survival_status', data=data,)\n",
    "plt.title(\"Class Distribution\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3 . **Preprocessing**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# a. Handling Missing Values\n",
    "print(\"Missing values:\\n\"+data.isnull().sum().to_string())\n",
    "\n",
    "data['age'] = data['age'].fillna(data['age'].mean()) # missing -> mean\n",
    "data = data.dropna(subset=['operation_year']) # missing -> drop\n",
    "data['nbr_axillary_nodes'] = data['nbr_axillary_nodes'].fillna(data['nbr_axillary_nodes'].median()) # missing -> median\n",
    "data = data.dropna(subset=['survival_status']) # missing -> drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# b. Handling outliers for \"nbr_axillary_nodes\"\n",
    "Q1 = data['nbr_axillary_nodes'].quantile(0.25)\n",
    "Q3 = data['nbr_axillary_nodes'].quantile(0.75)\n",
    "IQR = Q3 - Q1\n",
    "\n",
    "lower_bound = Q1 - 1.5 * IQR\n",
    "upper_bound = Q3 + 1.5 * IQR\n",
    "\n",
    "original_data = data.copy()\n",
    "data = data[(data['nbr_axillary_nodes'] >= lower_bound) & (data['nbr_axillary_nodes'] <= upper_bound)]\n",
    "\n",
    "# Create a figure with two subplots side by side\n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "# First subplot: Data without outliers\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(x=original_data['nbr_axillary_nodes'])\n",
    "plt.title(\"Data With Outliers\", fontsize=14)\n",
    "\n",
    "# Second subplot: Original data with outliers\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(x=data['nbr_axillary_nodes'])\n",
    "plt.title(\"Data without Outliers\", fontsize=14)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# c. Standarization \n",
    "data_before = data.copy()\n",
    "\n",
    "scaler = StandardScaler()\n",
    "data[['age', 'operation_year', 'nbr_axillary_nodes']] = scaler.fit_transform(data[['age', 'operation_year', 'nbr_axillary_nodes']])\n",
    "\n",
    "# Visualizing results \n",
    "plt.figure(figsize=(14, 6))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "sns.boxplot(data=data_before[['age', 'operation_year', 'nbr_axillary_nodes']])\n",
    "plt.title(\"Data Before Standardization\", fontsize=14)\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "sns.boxplot(data=data[['age', 'operation_year', 'nbr_axillary_nodes']])\n",
    "plt.title(\"Data After Standardization\", fontsize=14)\n",
    "\n",
    "# Adjust layout and display the plots\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. **cross-validation**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare the features and target\n",
    "X = data[['age', 'operation_year', 'nbr_axillary_nodes']]\n",
    "y = data['survival_status']\n",
    "dt_model = DecisionTreeClassifier(random_state=69)\n",
    "nb_model = GaussianNB()\n",
    "\n",
    "# Apply K-Fold Cross-Validation with random_state set to 69\n",
    "kfold = StratifiedKFold(n_splits=3, shuffle=True, random_state=69)  # 3 splits\n",
    "\n",
    "# Perform cross-validation\n",
    "dt_scores = cross_val_score(dt_model, X, y, cv=kfold)\n",
    "nb_scores = cross_val_score(nb_model, X, y, cv=kfold)\n",
    "\n",
    "print(f\"DT Scores: {dt_scores}\")\n",
    "print(f\"Mean: {dt_scores.mean():.2f}\")\n",
    "\n",
    "print(f\"\\nNB Scores: {nb_scores}\")\n",
    "print(f\"Mean: {nb_scores.mean():.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. **Classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Step 4: Split data into training and testing sets (80% train, 20% test)\n",
    "X = data[['age', 'operation_year', 'nbr_axillary_nodes']]\n",
    "y = data['survival_status']\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=69)\n",
    "\n",
    "# Decision Tree \n",
    "dt_model = DecisionTreeClassifier(random_state=69)      # Initialize model \n",
    "dt_model.fit(X_train, y_train)                          # Train model\n",
    "y_pred_dt = dt_model.predict(X_test)                    \n",
    "dt_accuracy = accuracy_score(y_test, y_pred_dt)         # Evaluate model\n",
    "dt_f1 = f1_score(y_test, y_pred_dt, average='weighted')\n",
    "dt_precision = precision_score(y_test, y_pred_dt, average='weighted')\n",
    "dt_recall = recall_score(y_test, y_pred_dt, average='weighted')\n",
    "\n",
    "# NB \n",
    "nb_model = GaussianNB()\n",
    "nb_model.fit(X_train, y_train)\n",
    "y_pred_nb = nb_model.predict(X_test)\n",
    "nb_accuracy = accuracy_score(y_test, y_pred_nb)\n",
    "nb_f1 = f1_score(y_test, y_pred_nb, average='weighted')\n",
    "nb_precision = precision_score(y_test, y_pred_nb, average='weighted')\n",
    "nb_recall = recall_score(y_test, y_pred_nb, average='weighted')\n",
    "\n",
    "\n",
    "# Save the results to a CSV file\n",
    "results = {\n",
    "    'Model': ['Decision Tree', 'Naive Bayes'],\n",
    "    'Accuracy': [dt_accuracy, nb_accuracy],\n",
    "    'F1-Score': [dt_f1, nb_f1]\n",
    "}\n",
    "\n",
    "results_df = pd.DataFrame(results)\n",
    "print(results_df)\n",
    "\n",
    "# Save to CSV\n",
    "results_df.to_csv('classification_results.csv', index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. **Handling Imbalanced Classes**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42, stratify=y)\n",
    "# Using SMOTE to oversample the minority class\n",
    "smote = SMOTE(random_state=69)\n",
    "X_train_smote, y_train_smote = smote.fit_resample(X, y)\n",
    "\n",
    "\n",
    "# Train the Decision Tree and Naive Bayes models with SMOTE data\n",
    "dt_smote = DecisionTreeClassifier(random_state=69)\n",
    "nb_smote = GaussianNB()\n",
    "dt_smote.fit(X_train_smote, y_train_smote)\n",
    "nb_smote.fit(X_train_smote, y_train_smote)\n",
    "\n",
    "# Predictions\n",
    "y_pred_dt = dt_smote.predict(X_test)\n",
    "y_pred_nb = nb_smote.predict(X_test)\n",
    "\n",
    "# Evaluate the models\n",
    "def evaluate_model(y_true, y_pred):\n",
    "    accuracy = accuracy_score(y_true, y_pred)\n",
    "    precision = precision_score(y_true, y_pred, average='weighted')\n",
    "    recall = recall_score(y_true, y_pred, average='weighted')\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted')\n",
    "    return accuracy, precision, recall, f1\n",
    "\n",
    "# Evaluate with SMOTE data\n",
    "dt_smote_accuracy, dt_smote_precision, dt_smote_recall, dt_smote_f1= evaluate_model(y_test, y_pred_dt)\n",
    "nb_smote_accuracy, nb_smote_precision, nb_smote_recall, nb_smote_f1= evaluate_model(y_test, y_pred_nb)\n",
    "\n",
    "# Print the results\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Decision Tree', 'Naive Bayes', 'Decision Tree (SMOTE)', 'Naive Bayes (SMOTE)'],\n",
    "    'Accuracy': [dt_accuracy, nb_accuracy, dt_smote_accuracy, nb_smote_accuracy],\n",
    "    'F1 Score': [dt_f1, nb_f1, dt_smote_f1, nb_smote_f1],\n",
    "    'Precision': [dt_precision,nb_precision, dt_smote_precision, nb_smote_precision],\n",
    "    'Recall': [dt_recall, nb_recall, dt_smote_recall, nb_smote_recall]\n",
    "})\n",
    "print(results)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set index to model names for easy visualization\n",
    "results.set_index('Model', inplace=True)\n",
    "\n",
    "# Prepare data for grouped bar plot\n",
    "metrics = ['Accuracy', 'F1 Score', 'Precision', 'Recall']\n",
    "models = ['Decision Tree', 'Naive Bayes', 'Decision Tree (SMOTE)', 'Naive Bayes (SMOTE)']\n",
    "\n",
    "# Create a DataFrame with metrics for easier visualization\n",
    "metric_data = results.T  # Transpose for grouping by metrics\n",
    "metric_data.columns = models\n",
    "\n",
    "# Plot grouped bar chart\n",
    "plt.figure(figsize=(14, 8))\n",
    "bar_width = 0.2\n",
    "x = range(len(metrics))\n",
    "\n",
    "# Plot bars for each model\n",
    "for i, model in enumerate(models):\n",
    "    plt.bar(\n",
    "        [pos + i * bar_width for pos in x],\n",
    "        metric_data[model],\n",
    "        width=bar_width,\n",
    "        label=model,\n",
    "        alpha=0.8\n",
    "    )\n",
    "\n",
    "# Add labels, title, and legend\n",
    "plt.title(\"Model Performance Comparison (Before and After SMOTE)\", fontsize=16)\n",
    "plt.xlabel(\"Metrics\", fontsize=14)\n",
    "plt.ylabel(\"Score\", fontsize=14)\n",
    "plt.xticks([pos + 1.5 * bar_width for pos in x], metrics, fontsize=12)\n",
    "plt.ylim(0, 1.1)\n",
    "plt.legend(title=\"Model\", fontsize=12)\n",
    "plt.grid(axis='y', linestyle='--', alpha=0.7)\n",
    "\n",
    "# Add value annotations\n",
    "for i, model in enumerate(models):\n",
    "    for j, value in enumerate(metric_data[model]):\n",
    "        plt.text(\n",
    "            j + i * bar_width,\n",
    "            value + 0.02,\n",
    "            f\"{value:.2f}\",\n",
    "            ha='center',\n",
    "            fontsize=10\n",
    "        )\n",
    "\n",
    "# Show the plot\n",
    "plt.tight_layout()\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handling Imbalanced Classes with SMOTE\n",
    "\n",
    "\n",
    "# Decision Tree with SMOTE\n",
    "dt_smote = DecisionTreeClassifier(random_state=42)\n",
    "dt_smote.fit(X_resampled, y_resampled)\n",
    "dt_smote_preds = dt_smote.predict(X_test)\n",
    "dt_smote_accuracy = accuracy_score(y_test, dt_smote_preds)\n",
    "dt_smote_f1 = f1_score(y_test, dt_smote_preds, average='weighted')\n",
    "\n",
    "# Naive Bayes with SMOTE\n",
    "nb_smote = GaussianNB()\n",
    "nb_smote.fit(X_resampled, y_resampled)\n",
    "nb_smote_preds = nb_smote.predict(X_test)\n",
    "nb_smote_accuracy = accuracy_score(y_test, nb_smote_preds)\n",
    "nb_smote_f1 = f1_score(y_test, nb_smote_preds, average='weighted')\n",
    "\n",
    "\n",
    "# Save results to CSV\n",
    "results = pd.DataFrame({\n",
    "    'Model': ['Decision Tree', 'Naive Bayes', 'Decision Tree (SMOTE)', 'Naive Bayes (SMOTE)'],\n",
    "    'Accuracy': [dt_accuracy, nb_accuracy, dt_smote_accuracy, nb_smote_accuracy],\n",
    "    'F1 Score': [dt_f1, nb_f1, dt_smote_f1, nb_smote_f1]\n",
    "})\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
